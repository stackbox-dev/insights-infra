apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: flink-session-cluster
  namespace: flink-studio
  labels:
    app.kubernetes.io/name: flink-session-cluster
    app.kubernetes.io/component: flink-cluster
    app.kubernetes.io/cloud: gcp
spec:
  image: asia-docker.pkg.dev/sbx-ci-cd/public/flink:latest
  flinkVersion: v2_0
  imagePullPolicy: Always
  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "2"
    # State backend optimized for persistent storage with GCS backup
    state.backend.type: "rocksdb"
    state.backend.incremental: "true"
    state.backend.rocksdb.memory.managed: "true"
    # Use persistent storage for RocksDB local state
    state.backend.rocksdb.localdir: "/data/flink-rocksdb"
    # Optimized for medium-sized jobs with 8GB memory, 50GB storage
    state.backend.rocksdb.memory.fixed-per-slot: "768mb" # Conservative for 8GB total memory
    # Balanced write buffers for medium-sized state
    state.backend.rocksdb.writebuffer.size: "128mb" # Good balance for medium jobs
    state.backend.rocksdb.writebuffer.count: "3" # Standard count for medium state
    # Moderate block cache for medium datasets
    state.backend.rocksdb.block.cache-size: "384mb" # Balanced cache size
    state.backend.rocksdb.thread.num: "2" # Conservative thread count
    # Configure memory ratios for medium-sized persistent storage
    state.backend.rocksdb.memory.write-buffer-ratio: "0.4"
    state.backend.rocksdb.memory.high-prio-pool-ratio: "0.08"
    # Enable changelog for continuous state uploading to GCS
    state.changelog.enabled: true
    state.changelog.storage: filesystem
    state.changelog.dstl.dfs.base-path: gs://sbx-stag-flink-storage/changelog
    # Force session cluster to start TaskManager pods immediately
    slotmanager.number-of-slots.min: "8"
    slotmanager.number-of-slots.max: "16"
    slotmanager.slot-request-timeout: "300000"
    # GCS paths for Flink state management
    state.checkpoints.dir: gs://sbx-stag-flink-storage/checkpoints
    state.savepoints.dir: gs://sbx-stag-flink-storage/savepoints
    high-availability.type: kubernetes
    high-availability.storageDir: gs://sbx-stag-flink-storage/ha
    restart-strategy.type: failure-rate
    restart-strategy.failure-rate.max-failures-per-interval: "10"
    restart-strategy.failure-rate.failure-rate-interval: "10 min"
    restart-strategy.failure-rate.delay: "30 s"
    execution.checkpointing.interval: "15 s"
    execution.checkpointing.mode: EXACTLY_ONCE
    execution.checkpointing.timeout: "10 min"
    execution.checkpointing.incremental: true
    execution.checkpointing.dir: gs://sbx-stag-flink-storage/flink-checkpoints
    # Additional checkpoint settings for maximum GCS usage
    execution.checkpointing.max-concurrent-checkpoints: 1
    execution.checkpointing.min-pause: "5 s"
    execution.checkpointing.tolerable-failure-number: 3
    # Reduce local state TTL to force more frequent GCS writes
    table.exec.state.ttl: "1 h"
    table.exec.source.idle-timeout: "30 s"
    # Job History and Archive Settings
    jobmanager.archive.fs.dir: gs://sbx-stag-flink-storage/archived-jobs
    web.history: 50
    web.checkpoints.history: 100
    web.exception-history-size: 50
    jobstore.cache-size: 104857600
    jobstore.expiration-time: 86400
    jobstore.max-capacity: 1000
    jobstore.type: File
    # Hadoop configuration for GCS with Workload Identity
    fs.gs.impl: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
    fs.AbstractFileSystem.gs.impl: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
    fs.gs.project.id: sbx-stag
    fs.gs.auth.service.account.enable: "true"
    # Use Application Default Credentials via Workload Identity
    fs.gs.auth.type: APPLICATION_DEFAULT
  serviceAccount: flink
  jobManager:
    resource:
      memory: "1536m"
      cpu: 1
    replicas: 1
    podTemplate:
      spec:
        serviceAccountName: flink
        containers:
          - name: flink-main-container
            env:
              - name: GOOGLE_CLOUD_PROJECT
                value: sbx-stag
              - name: AIVEN_KAFKA_BOOTSTRAP_SERVERS
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: bootstrap-servers
              - name: AIVEN_KAFKA_USERNAME
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: username
              - name: AIVEN_KAFKA_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: password
              - name: AIVEN_SCHEMA_REGISTRY_URL
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: schema-registry-url
        volumes: []
  taskManager:
    resource:
      memory: "8192m"
      cpu: 2
    replicas: 4
    podTemplate:
      spec:
        serviceAccountName: flink
        initContainers:
          - name: rocksdb-init
            image: busybox:1.35
            command: ["sh", "-c"]
            args:
              - |
                mkdir -p /data/flink-rocksdb
                chmod -R 777 /data/flink-rocksdb
                echo "RocksDB directory initialized successfully"
            volumeMounts:
              - name: rocksdb-storage
                mountPath: /data/flink-rocksdb
        containers:
          - name: flink-main-container
            resources:
              requests:
                memory: "8Gi"
                cpu: "2"
              limits:
                memory: "8Gi"
            env:
              - name: GOOGLE_CLOUD_PROJECT
                value: sbx-stag
              - name: AIVEN_KAFKA_BOOTSTRAP_SERVERS
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: bootstrap-servers
              - name: AIVEN_KAFKA_USERNAME
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: username
              - name: AIVEN_KAFKA_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: password
              - name: AIVEN_SCHEMA_REGISTRY_URL
                valueFrom:
                  secretKeyRef:
                    name: aiven-kafka-credentials
                    key: schema-registry-url
            volumeMounts:
              - name: rocksdb-storage
                mountPath: /data/flink-rocksdb
        volumes:
          - name: rocksdb-storage
            emptyDir:
              sizeLimit: 50Gi
  mode: native
---
apiVersion: v1
kind: Service
metadata:
  name: flink-session-cluster
  namespace: flink-studio
  labels:
    app.kubernetes.io/name: flink-session-cluster
    app.kubernetes.io/component: web-service
spec:
  selector:
    app: flink-session-cluster
    component: jobmanager
  ports:
    - name: web
      port: 80
      targetPort: 8081
      protocol: TCP
  type: ClusterIP
