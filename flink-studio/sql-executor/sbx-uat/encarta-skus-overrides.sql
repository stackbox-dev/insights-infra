SET 'pipeline.name' = 'Encarta SKUs Overrides Aggregation';
-- Create source tables (DDL for Kafka topics)
-- node_overrides source table
CREATE TABLE node_overrides (
    id STRING,
    principal_id BIGINT,
    sku_id STRING,
    node_id BIGINT,
    sku_short_description STRING,
    active BOOLEAN,
    sku_description STRING,
    active_from TIMESTAMP(3),
    active_till TIMESTAMP(3),
    fulfillment_type STRING,
    avg_l0_per_put INT,
    created_at TIMESTAMP(3),
    updated_at TIMESTAMP(3),
    l3_units INT,
    l2_units INT,
    layers INT,
    cases_per_layer INT,
    handling_unit_type STRING,
    is_deleted BOOLEAN,
    __snapshot STRING,
    is_snapshot AS COALESCE(__snapshot IN (
        'true',
        'first',
        'first_in_data_collection',
        'last_in_data_collection',
        'last'
    ), FALSE),
    PRIMARY KEY (id) NOT ENFORCED
) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'sbx_uat.encarta.public.node_overrides',
    'properties.bootstrap.servers' = 'sbx-stag-kafka-stackbox.e.aivencloud.com:22167',
    'properties.security.protocol' = 'SASL_SSL',
    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
    'properties.sasl.jaas.config' = 'org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";',
    'properties.ssl.truststore.location' = '/etc/kafka/secrets/kafka.truststore.jks',
    'properties.ssl.truststore.password' = '${TRUSTSTORE_PASSWORD}',
    'properties.ssl.endpoint.identification.algorithm' = 'https',
    'key.format' = 'avro-confluent',
    'key.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'key.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'key.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}',
    'value.format' = 'avro-confluent',
    'value.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'value.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}'
);
-- product_node_overrides source table
CREATE TABLE product_node_overrides (
    id STRING,
    principal_id BIGINT,
    node_id BIGINT,
    product_id STRING,
    min_quantity INT,
    max_quantity INT,
    order_lot INT,
    active BOOLEAN,
    created_at TIMESTAMP(3),
    updated_at TIMESTAMP(3),
    is_deleted BOOLEAN,
    __snapshot STRING,
    is_snapshot AS COALESCE(__snapshot IN (
        'true',
        'first',
        'first_in_data_collection',
        'last_in_data_collection',
        'last'
    ), FALSE),
    PRIMARY KEY (id) NOT ENFORCED
) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'sbx_uat.encarta.public.product_node_overrides',
    'properties.bootstrap.servers' = 'sbx-stag-kafka-stackbox.e.aivencloud.com:22167',
    'properties.security.protocol' = 'SASL_SSL',
    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
    'properties.sasl.jaas.config' = 'org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";',
    'properties.ssl.truststore.location' = '/etc/kafka/secrets/kafka.truststore.jks',
    'properties.ssl.truststore.password' = '${TRUSTSTORE_PASSWORD}',
    'properties.ssl.endpoint.identification.algorithm' = 'https',
    'key.format' = 'avro-confluent',
    'key.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'key.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'key.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}',
    'value.format' = 'avro-confluent',
    'value.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'value.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}'
);
-- skus_master source table (reusing from existing structure)
CREATE TABLE skus_master (
    id STRING NOT NULL,
    principal_id BIGINT NOT NULL,
    node_id BIGINT NOT NULL,
    category STRING,
    product STRING,
    product_id STRING,
    category_group STRING,
    sub_brand STRING,
    brand STRING,
    code STRING,
    name STRING,
    short_description STRING,
    description STRING,
    fulfillment_type STRING,
    avg_l0_per_put INT,
    inventory_type STRING,
    shelf_life INT,
    identifier1 STRING,
    identifier2 STRING,
    tag1 STRING,
    tag2 STRING,
    tag3 STRING,
    tag4 STRING,
    tag5 STRING,
    tag6 STRING,
    tag7 STRING,
    tag8 STRING,
    tag9 STRING,
    tag10 STRING,
    handling_unit_type STRING,
    cases_per_layer INT,
    layers INT,
    active_from TIMESTAMP(3),
    active_till TIMESTAMP(3),
    l0_units INT,
    l1_units INT,
    l2_units INT,
    l2_units_final INT,
    l3_units INT,
    l3_units_final INT,
    l0_name STRING,
    l0_weight DOUBLE,
    l0_volume DOUBLE,
    l0_package_type STRING,
    l0_length DOUBLE,
    l0_width DOUBLE,
    l0_height DOUBLE,
    l0_packing_efficiency DOUBLE,
    l0_itf_code STRING,
    l0_erp_weight DOUBLE,
    l0_erp_volume DOUBLE,
    l0_erp_length DOUBLE,
    l0_erp_width DOUBLE,
    l0_erp_height DOUBLE,
    l0_text_tag1 STRING,
    l0_text_tag2 STRING,
    l0_image STRING,
    l0_num_tag1 DOUBLE,
    l1_name STRING,
    l1_weight DOUBLE,
    l1_volume DOUBLE,
    l1_package_type STRING,
    l1_length DOUBLE,
    l1_width DOUBLE,
    l1_height DOUBLE,
    l1_packing_efficiency DOUBLE,
    l1_itf_code STRING,
    l1_erp_weight DOUBLE,
    l1_erp_volume DOUBLE,
    l1_erp_length DOUBLE,
    l1_erp_width DOUBLE,
    l1_erp_height DOUBLE,
    l1_text_tag1 STRING,
    l1_text_tag2 STRING,
    l1_image STRING,
    l1_num_tag1 DOUBLE,
    l2_name STRING,
    l2_weight DOUBLE,
    l2_volume DOUBLE,
    l2_package_type STRING,
    l2_length DOUBLE,
    l2_width DOUBLE,
    l2_height DOUBLE,
    l2_packing_efficiency DOUBLE,
    l2_itf_code STRING,
    l2_erp_weight DOUBLE,
    l2_erp_volume DOUBLE,
    l2_erp_length DOUBLE,
    l2_erp_width DOUBLE,
    l2_erp_height DOUBLE,
    l2_text_tag1 STRING,
    l2_text_tag2 STRING,
    l2_image STRING,
    l2_num_tag1 DOUBLE,
    l3_name STRING,
    l3_weight DOUBLE,
    l3_volume DOUBLE,
    l3_package_type STRING,
    l3_length DOUBLE,
    l3_width DOUBLE,
    l3_height DOUBLE,
    l3_packing_efficiency DOUBLE,
    l3_itf_code STRING,
    l3_erp_weight DOUBLE,
    l3_erp_volume DOUBLE,
    l3_erp_length DOUBLE,
    l3_erp_width DOUBLE,
    l3_erp_height DOUBLE,
    l3_text_tag1 STRING,
    l3_text_tag2 STRING,
    l3_image STRING,
    l3_num_tag1 DOUBLE,
    active BOOLEAN NOT NULL,
    classifications STRING NOT NULL,
    product_classifications STRING NOT NULL,
    is_deleted BOOLEAN NOT NULL,
    is_snapshot BOOLEAN NOT NULL,
    created_at TIMESTAMP(3) NOT NULL,
    updated_at TIMESTAMP(3) NOT NULL,
    PRIMARY KEY (id) NOT ENFORCED
) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'sbx_uat.encarta.public.skus_master',
    'properties.bootstrap.servers' = 'sbx-stag-kafka-stackbox.e.aivencloud.com:22167',
    'properties.security.protocol' = 'SASL_SSL',
    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
    'properties.sasl.jaas.config' = 'org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";',
    'properties.ssl.truststore.location' = '/etc/kafka/secrets/kafka.truststore.jks',
    'properties.ssl.truststore.password' = '${TRUSTSTORE_PASSWORD}',
    'properties.ssl.endpoint.identification.algorithm' = 'https',
    'key.format' = 'avro-confluent',
    'key.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'key.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'key.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}',
    'value.format' = 'avro-confluent',
    'value.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'value.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}'
);
-- Create sink table (destination table with same structure as skus_master)
CREATE TABLE skus_overrides (
    sku_id STRING NOT NULL,
    principal_id BIGINT NOT NULL,
    node_id BIGINT NOT NULL,
    category STRING,
    product STRING,
    product_id STRING,
    category_group STRING,
    sub_brand STRING,
    brand STRING,
    code STRING,
    name STRING,
    short_description STRING,
    description STRING,
    fulfillment_type STRING,
    avg_l0_per_put INT,
    inventory_type STRING,
    shelf_life INT,
    identifier1 STRING,
    identifier2 STRING,
    tag1 STRING,
    tag2 STRING,
    tag3 STRING,
    tag4 STRING,
    tag5 STRING,
    tag6 STRING,
    tag7 STRING,
    tag8 STRING,
    tag9 STRING,
    tag10 STRING,
    handling_unit_type STRING,
    cases_per_layer INT,
    layers INT,
    active_from TIMESTAMP(3),
    active_till TIMESTAMP(3),
    l0_units INT,
    l1_units INT,
    l2_units INT,
    l2_units_final INT,
    l3_units INT,
    l3_units_final INT,
    l0_name STRING,
    l0_weight DOUBLE,
    l0_volume DOUBLE,
    l0_package_type STRING,
    l0_length DOUBLE,
    l0_width DOUBLE,
    l0_height DOUBLE,
    l0_packing_efficiency DOUBLE,
    l0_itf_code STRING,
    l0_erp_weight DOUBLE,
    l0_erp_volume DOUBLE,
    l0_erp_length DOUBLE,
    l0_erp_width DOUBLE,
    l0_erp_height DOUBLE,
    l0_text_tag1 STRING,
    l0_text_tag2 STRING,
    l0_image STRING,
    l0_num_tag1 DOUBLE,
    l1_name STRING,
    l1_weight DOUBLE,
    l1_volume DOUBLE,
    l1_package_type STRING,
    l1_length DOUBLE,
    l1_width DOUBLE,
    l1_height DOUBLE,
    l1_packing_efficiency DOUBLE,
    l1_itf_code STRING,
    l1_erp_weight DOUBLE,
    l1_erp_volume DOUBLE,
    l1_erp_length DOUBLE,
    l1_erp_width DOUBLE,
    l1_erp_height DOUBLE,
    l1_text_tag1 STRING,
    l1_text_tag2 STRING,
    l1_image STRING,
    l1_num_tag1 DOUBLE,
    l2_name STRING,
    l2_weight DOUBLE,
    l2_volume DOUBLE,
    l2_package_type STRING,
    l2_length DOUBLE,
    l2_width DOUBLE,
    l2_height DOUBLE,
    l2_packing_efficiency DOUBLE,
    l2_itf_code STRING,
    l2_erp_weight DOUBLE,
    l2_erp_volume DOUBLE,
    l2_erp_length DOUBLE,
    l2_erp_width DOUBLE,
    l2_erp_height DOUBLE,
    l2_text_tag1 STRING,
    l2_text_tag2 STRING,
    l2_image STRING,
    l2_num_tag1 DOUBLE,
    l3_name STRING,
    l3_weight DOUBLE,
    l3_volume DOUBLE,
    l3_package_type STRING,
    l3_length DOUBLE,
    l3_width DOUBLE,
    l3_height DOUBLE,
    l3_packing_efficiency DOUBLE,
    l3_itf_code STRING,
    l3_erp_weight DOUBLE,
    l3_erp_volume DOUBLE,
    l3_erp_length DOUBLE,
    l3_erp_width DOUBLE,
    l3_erp_height DOUBLE,
    l3_text_tag1 STRING,
    l3_text_tag2 STRING,
    l3_image STRING,
    l3_num_tag1 DOUBLE,
    active BOOLEAN NOT NULL,
    classifications STRING NOT NULL,
    product_classifications STRING NOT NULL,
    is_deleted BOOLEAN NOT NULL,
    is_snapshot BOOLEAN NOT NULL,
    created_at TIMESTAMP(3) NOT NULL,
    updated_at TIMESTAMP(3) NOT NULL,
    PRIMARY KEY (sku_id, node_id) NOT ENFORCED
) WITH (
    'connector' = 'upsert-kafka',
    'topic' = 'sbx_uat.encarta.public.skus_overrides',
    'properties.bootstrap.servers' = 'sbx-stag-kafka-stackbox.e.aivencloud.com:22167',
    'properties.security.protocol' = 'SASL_SSL',
    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
    'properties.sasl.jaas.config' = 'org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";',
    'properties.ssl.truststore.location' = '/etc/kafka/secrets/kafka.truststore.jks',
    'properties.ssl.truststore.password' = '${TRUSTSTORE_PASSWORD}',
    'properties.ssl.endpoint.identification.algorithm' = 'https',
    'properties.transaction.id.prefix' = 'encarta-skus-overrides-agg',
    'key.format' = 'avro-confluent',
    'key.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'key.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'key.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}',
    'value.format' = 'avro-confluent',
    'value.avro-confluent.url' = 'https://sbx-stag-kafka-stackbox.e.aivencloud.com:22159',
    'value.avro-confluent.basic-auth.credentials-source' = 'USER_INFO',
    'value.avro-confluent.basic-auth.user-info' = '${KAFKA_USERNAME}:${KAFKA_PASSWORD}'
);
-- Continuously populate the overrides table from source tables
-- Records from node_overrides (SKU-specific overrides) with product overrides as fallback
INSERT INTO skus_overrides
SELECT sno.sku_id,
    sno.principal_id,
    sno.node_id,
    sm.category,
    sm.product,
    sm.product_id,
    sm.category_group,
    sm.sub_brand,
    sm.brand,
    sm.code,
    sm.name,
    -- Apply node overrides for short_description if available
    COALESCE(sno.sku_short_description, sm.short_description) AS short_description,
    -- Apply node overrides for description if available
    COALESCE(sno.sku_description, sm.description) AS description,
    -- Apply node overrides for fulfillment_type if available
    COALESCE(sno.fulfillment_type, sm.fulfillment_type) AS fulfillment_type,
    -- Apply node overrides for avg_l0_per_put if available
    COALESCE(sno.avg_l0_per_put, sm.avg_l0_per_put) AS avg_l0_per_put,
    sm.inventory_type,
    sm.shelf_life,
    sm.identifier1,
    sm.identifier2,
    sm.tag1,
    sm.tag2,
    sm.tag3,
    sm.tag4,
    sm.tag5,
    sm.tag6,
    sm.tag7,
    sm.tag8,
    sm.tag9,
    sm.tag10,
    -- Apply node overrides for handling_unit_type if available
    COALESCE(sno.handling_unit_type, sm.handling_unit_type) AS handling_unit_type,
    -- Apply node overrides for cases_per_layer if available
    COALESCE(sno.cases_per_layer, sm.cases_per_layer) AS cases_per_layer,
    -- Apply node overrides for layers if available
    COALESCE(sno.layers, sm.layers) AS layers,
    -- Apply node overrides for active_from if available
    COALESCE(sno.active_from, sm.active_from) AS active_from,
    -- Apply node overrides for active_till if available
    COALESCE(sno.active_till, sm.active_till) AS active_till,
    sm.l0_units,
    sm.l1_units,
    sm.l2_units,
    -- Apply node overrides for l2_units_final if available
    COALESCE(sno.l2_units, sm.l2_units_final) AS l2_units_final,
    sm.l3_units,
    -- Apply node overrides for l3_units_final if available
    COALESCE(sno.l3_units, sm.l3_units_final) AS l3_units_final,
    sm.l0_name,
    sm.l0_weight,
    sm.l0_volume,
    sm.l0_package_type,
    sm.l0_length,
    sm.l0_width,
    sm.l0_height,
    sm.l0_packing_efficiency,
    sm.l0_itf_code,
    sm.l0_erp_weight,
    sm.l0_erp_volume,
    sm.l0_erp_length,
    sm.l0_erp_width,
    sm.l0_erp_height,
    sm.l0_text_tag1,
    sm.l0_text_tag2,
    sm.l0_image,
    sm.l0_num_tag1,
    sm.l1_name,
    sm.l1_weight,
    sm.l1_volume,
    sm.l1_package_type,
    sm.l1_length,
    sm.l1_width,
    sm.l1_height,
    sm.l1_packing_efficiency,
    sm.l1_itf_code,
    sm.l1_erp_weight,
    sm.l1_erp_volume,
    sm.l1_erp_length,
    sm.l1_erp_width,
    sm.l1_erp_height,
    sm.l1_text_tag1,
    sm.l1_text_tag2,
    sm.l1_image,
    sm.l1_num_tag1,
    sm.l2_name,
    sm.l2_weight,
    sm.l2_volume,
    sm.l2_package_type,
    sm.l2_length,
    sm.l2_width,
    sm.l2_height,
    sm.l2_packing_efficiency,
    sm.l2_itf_code,
    sm.l2_erp_weight,
    sm.l2_erp_volume,
    sm.l2_erp_length,
    sm.l2_erp_width,
    sm.l2_erp_height,
    sm.l2_text_tag1,
    sm.l2_text_tag2,
    sm.l2_image,
    sm.l2_num_tag1,
    sm.l3_name,
    sm.l3_weight,
    sm.l3_volume,
    sm.l3_package_type,
    sm.l3_length,
    sm.l3_width,
    sm.l3_height,
    sm.l3_packing_efficiency,
    sm.l3_itf_code,
    sm.l3_erp_weight,
    sm.l3_erp_volume,
    sm.l3_erp_length,
    sm.l3_erp_width,
    sm.l3_erp_height,
    sm.l3_text_tag1,
    sm.l3_text_tag2,
    sm.l3_image,
    sm.l3_num_tag1,
    -- Apply node overrides first, then product overrides, then master data
    COALESCE(sno.active, pno.active, sm.active) AS active,
    sm.classifications,
    sm.product_classifications,
    COALESCE(sno.is_deleted, pno.is_deleted, sm.is_deleted) AS is_deleted,
    sm.is_snapshot,
    sm.created_at,
    -- Update timestamp should reflect the latest change from any source
    GREATEST(
        COALESCE(sm.updated_at, TIMESTAMP '1970-01-01 00:00:00'),
        COALESCE(sno.updated_at, TIMESTAMP '1970-01-01 00:00:00'),
        COALESCE(pno.updated_at, TIMESTAMP '1970-01-01 00:00:00')
    ) AS updated_at
FROM node_overrides sno
    INNER JOIN skus_master sm ON sno.sku_id = sm.id
    LEFT JOIN product_node_overrides pno ON sm.product_id = pno.product_id
    AND sno.node_id = pno.node_id
    AND COALESCE(pno.is_deleted, FALSE) = FALSE
WHERE COALESCE(sno.is_deleted, FALSE) = FALSE
    AND COALESCE(sm.is_deleted, FALSE) = FALSE
UNION ALL
-- Records from product_node_overrides (product-level overrides) 
-- Only for SKUs that don't have node-specific overrides
SELECT sm.id AS sku_id,
    pno.principal_id,
    pno.node_id,
    sm.category,
    sm.product,
    sm.product_id,
    sm.category_group,
    sm.sub_brand,
    sm.brand,
    sm.code,
    sm.name,
    sm.short_description,
    sm.description,
    sm.fulfillment_type,
    sm.avg_l0_per_put,
    sm.inventory_type,
    sm.shelf_life,
    sm.identifier1,
    sm.identifier2,
    sm.tag1,
    sm.tag2,
    sm.tag3,
    sm.tag4,
    sm.tag5,
    sm.tag6,
    sm.tag7,
    sm.tag8,
    sm.tag9,
    sm.tag10,
    sm.handling_unit_type,
    sm.cases_per_layer,
    sm.layers,
    sm.active_from,
    sm.active_till,
    sm.l0_units,
    sm.l1_units,
    sm.l2_units,
    sm.l2_units_final,
    sm.l3_units,
    sm.l3_units_final,
    sm.l0_name,
    sm.l0_weight,
    sm.l0_volume,
    sm.l0_package_type,
    sm.l0_length,
    sm.l0_width,
    sm.l0_height,
    sm.l0_packing_efficiency,
    sm.l0_itf_code,
    sm.l0_erp_weight,
    sm.l0_erp_volume,
    sm.l0_erp_length,
    sm.l0_erp_width,
    sm.l0_erp_height,
    sm.l0_text_tag1,
    sm.l0_text_tag2,
    sm.l0_image,
    sm.l0_num_tag1,
    sm.l1_name,
    sm.l1_weight,
    sm.l1_volume,
    sm.l1_package_type,
    sm.l1_length,
    sm.l1_width,
    sm.l1_height,
    sm.l1_packing_efficiency,
    sm.l1_itf_code,
    sm.l1_erp_weight,
    sm.l1_erp_volume,
    sm.l1_erp_length,
    sm.l1_erp_width,
    sm.l1_erp_height,
    sm.l1_text_tag1,
    sm.l1_text_tag2,
    sm.l1_image,
    sm.l1_num_tag1,
    sm.l2_name,
    sm.l2_weight,
    sm.l2_volume,
    sm.l2_package_type,
    sm.l2_length,
    sm.l2_width,
    sm.l2_height,
    sm.l2_packing_efficiency,
    sm.l2_itf_code,
    sm.l2_erp_weight,
    sm.l2_erp_volume,
    sm.l2_erp_length,
    sm.l2_erp_width,
    sm.l2_erp_height,
    sm.l2_text_tag1,
    sm.l2_text_tag2,
    sm.l2_image,
    sm.l2_num_tag1,
    sm.l3_name,
    sm.l3_weight,
    sm.l3_volume,
    sm.l3_package_type,
    sm.l3_length,
    sm.l3_width,
    sm.l3_height,
    sm.l3_packing_efficiency,
    sm.l3_itf_code,
    sm.l3_erp_weight,
    sm.l3_erp_volume,
    sm.l3_erp_length,
    sm.l3_erp_width,
    sm.l3_erp_height,
    sm.l3_text_tag1,
    sm.l3_text_tag2,
    sm.l3_image,
    sm.l3_num_tag1,
    -- Apply product overrides first, then master data
    COALESCE(pno.active, sm.active) AS active,
    sm.classifications,
    sm.product_classifications,
    COALESCE(pno.is_deleted, sm.is_deleted) AS is_deleted,
    sm.is_snapshot,
    sm.created_at,
    -- Update timestamp should reflect the latest change from any source
    GREATEST(
        COALESCE(sm.updated_at, TIMESTAMP '1970-01-01 00:00:00'),
        COALESCE(pno.updated_at, TIMESTAMP '1970-01-01 00:00:00')
    ) AS updated_at
FROM product_node_overrides pno
    INNER JOIN skus_master sm ON pno.product_id = sm.product_id
    LEFT JOIN node_overrides sno2 ON sno2.sku_id = sm.id
    AND sno2.node_id = pno.node_id
    AND COALESCE(sno2.is_deleted, FALSE) = FALSE
WHERE COALESCE(pno.is_deleted, FALSE) = FALSE
    AND COALESCE(sm.is_deleted, FALSE) = FALSE -- Exclude SKUs that already have node-specific overrides for this node
    AND sno2.sku_id IS NULL;